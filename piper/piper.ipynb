{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF GPU\n",
    "!pip install piper-tts\n",
    "!pip install onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no GPU\n",
    "!pip install piper-tts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir piper_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import wave\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from piper import PiperVoice\n",
    "from piper.download import ensure_voice_exists, find_voice, get_voices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download voices that you want to use: \n",
    "[voices](https://github.com/rhasspy/piper/blob/master/VOICES.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_GB-alan-low\n",
    "!wget https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_GB/alan/low/en_GB-alan-low.onnx?download=true -O en_GB-alan-low.onnx\n",
    "!wget https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_GB/alan/low/en_GB-alan-low.onnx.json?download=true.json -O en_GB-alan-low.onnx.json\n",
    "\n",
    "# en_GB-alan-medium\n",
    "!wget https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_GB/alan/medium/en_GB-alan-medium.onnx?download=true -O en_GB-alan-medium.onnx\n",
    "!wget https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_GB/alan/medium/en_GB-alan-medium.onnx.json?download=true.json -O en_GB-alan-medium.onnx\n",
    "\n",
    "# en_US-lessac-high\n",
    "!wget https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_US/lessac/high/en_US-lessac-high.onnx?download=true -O en_US-lessac-high.onnx\n",
    "!wget https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_US/lessac/high/en_US-lessac-high.onnx.json?download=true.json -O en_US-lessac-high.onnx\n",
    "\n",
    "# en_GB-northern_english_male-medium\n",
    "!wget https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_GB/northern_english_male/medium/en_GB-northern_english_male-medium.onnx?download=true -O en_GB-northern_english_male-medium.onnx\n",
    "!wget https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/en/en_GB/northern_english_male/medium/en_GB-northern_english_male-medium.onnx.json?download=true.json -O en_GB-northern_english_male-medium.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = {\n",
    "    \"en_GB-alan-low\": [],\n",
    "    \"en_GB-alan-medium\": [],\n",
    "    \"en_GB-northern_english_male-medium\": [],\n",
    "    \"en_US-lessac-high\": [],\n",
    "}\n",
    "text = \"This is sample text that will be convert to speech.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_list.keys():\n",
    "    print(f\"Inference for {model_name} model on {device} started.\")\n",
    "    download_dir=''\n",
    "    data_dir=['']\n",
    "\n",
    "    speaker=None\n",
    "    length_scale=None\n",
    "    noise_scale=None\n",
    "    noise_w=None\n",
    "    sentence_silence=0.0\n",
    "    if torch.cuda.is_available():\n",
    "      cuda = True\n",
    "    else:\n",
    "      cuda=False\n",
    "    update_voices=False\n",
    "    debug=False\n",
    "\n",
    "    model=f'{download_dir}{model_name}.onnx'\n",
    "    config=f'{download_dir}{model_name}.onnx.json'\n",
    "    if cuda:\n",
    "        output_file_name = f\"piper_output/gpu_{model_name}.onnx.wav\"\n",
    "    else:\n",
    "        output_file_name = f\"piper_output/cpu_{model_name}.onnx.wav\"\n",
    "\n",
    "    model_path = Path(model)\n",
    "\n",
    "    if not model_path.exists():\n",
    "        voices_info = get_voices(download_dir, update_voices=update_voices)\n",
    "        aliases_info: Dict[str, Any] = {}\n",
    "        for voice_info in voices_info.values():\n",
    "            for voice_alias in voice_info.get(\"aliases\", []):\n",
    "                aliases_info[voice_alias] = {\"_is_alias\": True, **voice_info}\n",
    "\n",
    "        voices_info.update(aliases_info)\n",
    "        ensure_voice_exists(model, data_dir, download_dir, voices_info)\n",
    "        model, config = find_voice(model, data_dir)\n",
    "\n",
    "    voice = PiperVoice.load(model, config_path=config, use_cuda=cuda)\n",
    "    synthesize_args = {\n",
    "        \"speaker_id\": speaker,\n",
    "        \"length_scale\": length_scale,\n",
    "        \"noise_scale\": noise_scale,\n",
    "        \"noise_w\": noise_w,\n",
    "        \"sentence_silence\": sentence_silence,\n",
    "    }\n",
    "\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        raise ValueError(\"No text provided\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    with wave.open(output_file_name, \"wb\") as wav_file:\n",
    "        voice.synthesize(text, wav_file, **synthesize_args)\n",
    "    print(f\"Inference Time: {time.time() - start_time}\")\n",
    "    print(f\"Inference for {model_name} model ended.\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
